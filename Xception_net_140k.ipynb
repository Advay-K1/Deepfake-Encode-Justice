{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7517bb03-7bbb-41ff-9627-267e9f020816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import kagglehub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8270a6d0-9720-490c-9c75-3ded833ea2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.4-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging in /Users/advaykadam/anaconda3/envs/machine-learning-env/lib/python3.11/site-packages (from kagglehub) (23.1)\n",
      "Requirement already satisfied: requests in /Users/advaykadam/anaconda3/envs/machine-learning-env/lib/python3.11/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/advaykadam/anaconda3/envs/machine-learning-env/lib/python3.11/site-packages (from kagglehub) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/advaykadam/anaconda3/envs/machine-learning-env/lib/python3.11/site-packages (from requests->kagglehub) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/advaykadam/anaconda3/envs/machine-learning-env/lib/python3.11/site-packages (from requests->kagglehub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/advaykadam/anaconda3/envs/machine-learning-env/lib/python3.11/site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/advaykadam/anaconda3/envs/machine-learning-env/lib/python3.11/site-packages (from requests->kagglehub) (2023.7.22)\n",
      "Downloading kagglehub-0.3.4-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0636267c-6706-4cb2-894a-12fb741c8f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/advaykadam/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = kagglehub.dataset_download(\"xhlulu/140k-real-and-fake-faces\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79b74901-a916-401b-96a7-8889dbe092df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "train_data_dir = os.path.join(path, 'real_vs_fake/real-vs-fake/train')\n",
    "\n",
    "test_data_dir = os.path.join(path, 'real_vs_fake/real-vs-fake/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d477cf3-800d-49f2-af6d-3985e7b1c693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "target_size = (224, 224)\n",
    "batch_size = 100  \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size= target_size, \n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary', \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d23ce98-5888-4ead-b6f9-44e33fff09ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fake': 0, 'real': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1dbf81d2-6a4e-4e6f-8d18-f7b777513fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers.legacy import Adam  \n",
    "\n",
    "def build_model():\n",
    "    shape = (224, 224, 3)\n",
    "    \n",
    "    Xception_mod_trained = Xception(input_shape=shape, include_top=False, weights='imagenet')  \n",
    "    \n",
    "    \n",
    "    final_model_transfer = Sequential()\n",
    "    \n",
    "    final_model_transfer.add(Xception_mod_trained)\n",
    "    \n",
    "    final_model_transfer.add(layers.GlobalAveragePooling2D())\n",
    "    final_model_transfer.add(layers.Dense(1024, activation='relu'))\n",
    "    final_model_transfer.add(layers.Dropout(0.5))\n",
    "    \n",
    "    final_model_transfer.add(layers.Dense(1, activation='sigmoid'))  \n",
    "    \n",
    "    final_model_transfer.compile(optimizer=Adam(learning_rate=1e-5), metrics=['accuracy'], loss = 'binary_crossentropy')\n",
    "\n",
    "\n",
    "    return final_model_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bc3d7a2-a6fa-4cea-ab8b-f6be78c76b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22960681 (87.59 MB)\n",
      "Trainable params: 22906153 (87.38 MB)\n",
      "Non-trainable params: 54528 (213.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model_transfer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4fbbfc4-c7bd-4187-ac1a-c20713ea85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'model_checkpoint_{epoch:03d}.h5',  \n",
    "    save_weights_only=True,  \n",
    "    save_freq='epoch', \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51dbd8a9-38a3-40e1-add4-f5b6a04ee42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_in_chunks(train_generator, model, batch_size=100, chunk_size=10000, checkpoint_callback=None):\n",
    "\n",
    "    total_samples = train_generator.samples \n",
    "    \n",
    "    steps_per_chunk = chunk_size // batch_size  \n",
    "    \n",
    "    for start_idx in range(0, total_samples, chunk_size):\n",
    "\n",
    "        end_idx = min(start_idx + chunk_size, total_samples)\n",
    "        \n",
    "     \n",
    "        model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=steps_per_chunk,\n",
    "            epochs=1, \n",
    "            callbacks=[checkpoint_callback]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9536bd82-30fe-4e2d-a45c-0d8ee573c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a9e8b0a-281c-4d29-916f-22936dde0088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.6622 \n",
      "Epoch 1: saving model to model_checkpoint_001.h5\n",
      "100/100 [==============================] - 1355s 14s/step - loss: 0.6239 - accuracy: 0.6622\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4664 - accuracy: 0.7951 \n",
      "Epoch 1: saving model to model_checkpoint_001.h5\n",
      "100/100 [==============================] - 1309s 13s/step - loss: 0.4664 - accuracy: 0.7951\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3407 - accuracy: 0.8602 \n",
      "Epoch 1: saving model to model_checkpoint_001.h5\n",
      "100/100 [==============================] - 1332s 13s/step - loss: 0.3407 - accuracy: 0.8602\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.8940 \n",
      "Epoch 1: saving model to model_checkpoint_001.h5\n",
      "100/100 [==============================] - 1346s 13s/step - loss: 0.2606 - accuracy: 0.8940\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.9202 \n",
      "Epoch 1: saving model to model_checkpoint_001.h5\n",
      "100/100 [==============================] - 1320s 13s/step - loss: 0.2040 - accuracy: 0.9202\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.9337 \n",
      "Epoch 1: saving model to model_checkpoint_001.h5\n",
      "100/100 [==============================] - 1389s 14s/step - loss: 0.1713 - accuracy: 0.9337\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.9453 \n",
      "Epoch 1: saving model to model_checkpoint_001.h5\n",
      "100/100 [==============================] - 1434s 14s/step - loss: 0.1466 - accuracy: 0.9453\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.9519 \n",
      "Epoch 1: saving model to model_checkpoint_001.h5\n",
      "100/100 [==============================] - 1310s 13s/step - loss: 0.1332 - accuracy: 0.9519\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9630 \n",
      "Epoch 1: saving model to model_checkpoint_001.h5\n",
      "100/100 [==============================] - 1259s 13s/step - loss: 0.1050 - accuracy: 0.9630\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9671 \n",
      "Epoch 1: saving model to model_checkpoint_001.h5\n",
      "100/100 [==============================] - 1352s 14s/step - loss: 0.0921 - accuracy: 0.9671\n"
     ]
    }
   ],
   "source": [
    "train_in_chunks(train_generator, tran_model, chunk_size=10000, batch_size=100, checkpoint_callback=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ca290-7f47-4108-ab5c-325baa5e65d2",
   "metadata": {},
   "source": [
    "Test Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d01e668-2751-4d62-b481-0a69da6c0f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "target_size = (224, 224)\n",
    "batch_size = 100  \n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size= target_size, \n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary', \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59163a25-ec21-4629-b29d-4c1cdf8742e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fake': 0, 'real': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15399a57-b9c4-4be9-953c-254d0904f07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 536s 3s/step - loss: 0.1034 - accuracy: 0.9607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10337487608194351, 0.9606500267982483]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc8b32-89da-4aab-a82c-20373bb9bf10",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e4ffb-180f-478d-bfa4-5f42148f6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_model.save(\"transfer_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine-learning-env] *",
   "language": "python",
   "name": "conda-env-machine-learning-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
